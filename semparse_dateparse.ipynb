{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 5: Semantic date parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "__author__ = \"Christopher Potts\"\n",
    "__version__ = \"CS224u, Stanford, Spring 2018 term\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contents\n",
    "\n",
    "0. [Submission](#Submission)\n",
    "0. [Set-up](#Set-up)\n",
    "0. [Goals](#Goals)\n",
    "0. [Dataset](#Dataset)\n",
    "0. [Core interpretive functionality](#Core-interpretive-functionality)\n",
    "0. [Questions 1–6: Build the crude grammar [6 points]](#Questions-1–6:-Build-the-crude-grammar-[6-points])\n",
    "0. [Check oracle accuracy](#Check-oracle-accuracy)\n",
    "0. [Question 7: Timezone sensitivity [2 points]](#Question-7:-Timezone-sensitivity-[2-points])\n",
    "0. [Question 8: Year-string length [2 points]](#Question-8:-Year-string-length-[2-points])\n",
    "0. [Putting the feature functions together](#Putting-the-feature-functions-together)\n",
    "0. [Train a model](#Train-a-model)\n",
    "0. [Evaluate the trained model](#Evaluate-the-trained-model)\n",
    "0. [A rule-based baseline](#A-rule-based-baseline)\n",
    "0. [Inspect the trained model](#Inspect-the-trained-model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission\n",
    "\n",
    "For this homework, the submission procedure is a bit different than before:\n",
    "    \n",
    "1. Run the complete notebook, or at least up to the section 'A rule-based baseline'. (It's probably easier to just run the whole notebook.) Leave all the output embedded.\n",
    "1. Save the notebook and upload the notebook file to Canvas: https://canvas.stanford.edu/courses/83399/assignments/135084\n",
    "\n",
    "It's fine to add cells for your work, but don't delete any, so that we're sure we have the output we need for evaluation.\n",
    "\n",
    "As usual, evaluating your work is not really our central goal. In fact, we've included various tests and checks to help ensure that you do everything correctly. Our goal is to give you the experience of designing and optimizing a semantic parser that could have real-world applicability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set-up\n",
    "\n",
    "0. Make sure the `sys.path.append` value is the path to your local [SippyCup repository](https://github.com/wcmac/sippycup). (Alternatively, you can add SippyCup to your Python path; see one of the teaching team if you'd like to do that but aren't sure how.)\n",
    "\n",
    "0. Make sure that `semparse_dateparse_data.py` is in the current directory (or available via your Python path)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../sippycup')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import re\n",
    "import calendar\n",
    "import itertools\n",
    "import random\n",
    "from collections import defaultdict\n",
    "from datetime import date\n",
    "from dateutil import parser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goals\n",
    "\n",
    "The goal of this homework is to train a semantic parser to interpret date strings. Although this requires only simple syntactic structures, it turns out to be a deep understanding challenge involving contextual inference. Date strings are often ambiguous, and there are conventions for how to resolve the ambiguities. For example, _1/2/11_ is ambiguous between `Jan 2` and `Feb 1`, and the _11_ could pick out `1211`, `1911`, `2011`, and so forth.\n",
    "\n",
    "The homework is structured basically as our bake-off was: the first goal is to create a grammar that gets perfect oracle accuracy, and the second goal is to design features that resolve ambiguities accurately and so predict the correct denotations.\n",
    "\n",
    "In this case, it's possible to write a high-quality grammar right from the start. We know (approximately) what most of the words mean, so we really just need to handle the variation in the forms people use. The bigger challenge comes in defining features that capture the subtler interpretive conventions.\n",
    "\n",
    "In the final part, we bring in a baseline: the rule-based `dateutil.parser.parse`. It's good, achieving around 70% on the train and dev sets. However, there are some strings that it just can't parse, and, since it isn't learning-based, it can't learn the conventions latent in the data. You'll be able to do much better!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset has `train` and `dev` portions, with 1000 and 500 examples, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from semparse_dateparse_data import dateparse_train, dateparse_dev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a look at the data via random samples. Running this cell a few times will give you a feel for the data.\n",
    "\n",
    "* All the punctuation has been removed from the strings for convenience.\n",
    "\n",
    "* All of the examples end with one of two informal timezone flags: `US` if the string comes from text produced in the U.S., and `non-US` otherwise. This is an important piece of information that can be used in learning, since (I assume) only Americans use the jumbled `month/day/year` order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display a random sample of training examples:\n",
    "for ex in random.sample(dateparse_train, k=5):    \n",
    "    print(\"=\" * 70)\n",
    "    print(\"Input: {}\".format(ex.input))\n",
    "    print(\"Denotation: {}\".format(repr(ex.denotation)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Core interpretive functionality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's the semantics you'll want to use. You won't need to change it. \n",
    "\n",
    "__Important__: `date_semantics` expects its arguments in international order: `year, month, day`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def date_semantics(year, month, day):\n",
    "    \"\"\"Interpret the arguments as a date objects if possible. Returns \n",
    "    None of the datetime module won't treat the arguments as a date \n",
    "    (say, because it would be a Feb 31).\"\"\"\n",
    "    try:\n",
    "        return date(year=year, month=month, day=day)\n",
    "    except ValueError:\n",
    "        return None\n",
    "\n",
    "# The key dt is arbitrary, but the grammar rules need to hook into it.\n",
    "ops = {'dt': date_semantics}\n",
    "\n",
    "def execute(semantics):\n",
    "    \"\"\"The usual SippyCup interpretation function\"\"\"\n",
    "    if isinstance(semantics, tuple):\n",
    "        op = ops[semantics[0]]\n",
    "        args = [execute(arg) for arg in semantics[1:]]\n",
    "        return op(*args)\n",
    "    else:\n",
    "        return semantics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions 1–6: Build the crude grammar [6 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following is a high-level summary of the grammar you're trying to build. Rules in green have been completed for you. Rules in orange still need to be written.\n",
    "\n",
    "![dateparse-grammar-summary.png](fig/dateparse-grammar-summary.png)\n",
    "\n",
    "It's easy to accidentally add repeated rules and problematic rules to a grammar, forget that one has done that, and then plunge into a pit of grammatical despair as one deals with the bugs this introduces. To help prevent this, you'll write the entire grammar in a single cell of this notebook, to ensure that reloading the cell gives you a fresh start. So questions 1–6 are in the next cell, along with the rules we wrote for you (and a lot of hints)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from parsing import Grammar, Rule, add_rule\n",
    "\n",
    "\n",
    "# Use $DATE for the root node of its full date expressions:\n",
    "gram = Grammar(start_symbol=\"$DATE\")\n",
    "\n",
    "# Fill this with Rule objects:\n",
    "rules = []\n",
    "\n",
    "\n",
    "######################################################################\n",
    "################# TIMEZONE RULES (ALREADY COMPLETED) #################\n",
    "\n",
    "# Make sure the grammar can handle final timezone information:\n",
    "timezone_rules = [\n",
    "    Rule('$DATE', '$DATE $TZ', (lambda sems : sems[0])),\n",
    "    Rule('$TZ', 'US'),\n",
    "    Rule('$TZ', 'non-US') ]\n",
    "\n",
    "rules += timezone_rules\n",
    "\n",
    "\n",
    "######################################################################\n",
    "################ RULES FOR MONTHS (ALREADY COMPLETED) ################\n",
    "#\n",
    "# As a reminder about the notation, concepts, etc., here are lexical \n",
    "# rules for the months. They all determine trees\n",
    "# \n",
    "#    $M : i\n",
    "#      |\n",
    "#  monthname\n",
    "#\n",
    "# where monthname is the ith month of the year.\n",
    "\n",
    "# Full month names with \"\" in the 0th position so that 'January' has \n",
    "# index 1, 'February' index 2, ...\n",
    "months = [str(s) for s in calendar.month_name]\n",
    "# Add the rules:\n",
    "rules += [Rule('$M', m, i) for i, m in enumerate(months) if m]\n",
    "\n",
    "# 3-letter month names like \"Jan\", \"Feb\", with \"\" in 0th position:\n",
    "mos = [str(s) for s in calendar.month_abbr]\n",
    "# Add the rules:\n",
    "rules += [Rule('$M', m, i) for i, m in enumerate(mos) if m]\n",
    "\n",
    "# Numerical months:\n",
    "num_months = [str(i) for i in range(1, 13)]\n",
    "# Add the rules:\n",
    "rules += [Rule('$M', m, int(m)) for m in num_months]\n",
    "\n",
    "# 1-digit months with an initial zero:\n",
    "num_months_padded = [str(i).zfill(2) for i in range(1,10)]\n",
    "# Add the rules:\n",
    "rules += [Rule('$M', m, int(m)) for m in num_months_padded]\n",
    "        \n",
    "    \n",
    "######################################################################\n",
    "# Question 1: Rules for integer days\n",
    "#\n",
    "# Add lexical rules for the days. Again, these will be structures\n",
    "#\n",
    "#   $D : i\n",
    "#     |\n",
    "#    day\n",
    "# \n",
    "# where day is a 1- or 2-digit string and i is its corresponding int.\n",
    "\n",
    "# Here are days of the month without and with two-digit padding. Each \n",
    "# day string m can be interpreted semantically as int(m).\n",
    "\n",
    "days = [str(d) for d in range(1, 32)]\n",
    "\n",
    "days_padded = [str(i).zfill(2) for i in range(1, 11)]\n",
    "\n",
    "# Add to the rules list here:\n",
    "\n",
    "\n",
    "\n",
    "######################################################################\n",
    "# Question 2: Rules for ordinal days  \n",
    "#\n",
    "# The data contain day names like \"2nd\". Use int2ordinal to create \n",
    "# rules for these too:\n",
    "#\n",
    "#   $D : int(i)\n",
    "#        |\n",
    "#  int2ordinal(i)\n",
    "#\n",
    "# The meaning of these expressions is the corresponding int -- e.g.,\n",
    "# '2nd' means 2 and '21st' means 21.\n",
    "\n",
    "def int2ordinal(s):\n",
    "    \"\"\"Forms numerals like \"1st\" from int strs like 1\"\"\"\n",
    "    suffixes = {\"1\": \"st\", \"2\": \"nd\", \"3\": \"rd\"}    \n",
    "    if len(s) == 2 and s[0] == '1': # teens\n",
    "        suff = \"th\"\n",
    "    else: # all others use suffixes or default to \"th\"\n",
    "        suff = suffixes.get(s[-1], \"th\")\n",
    "    return s + suff\n",
    "\n",
    "# Add to the rules list here; you can use `days` above for the \n",
    "# core meanings.\n",
    "\n",
    "\n",
    "\n",
    "######################################################################\n",
    "# Question 3: Rules for 'the'\n",
    "#\n",
    "# The data contain expressions like \"the 3rd\". Add a lexical rule to \n",
    "# include 'the', and a binary combination rule so that we have \n",
    "# structures like\n",
    "#\n",
    "#      $D\n",
    "#     /  \\ \n",
    "#   $Det  $D\n",
    "#    |    |\n",
    "#   the  3rd\n",
    "#\n",
    "# We emphasize that this requires *two* new rules: one to add 'the' \n",
    "# as a $Det, and another to allow for the parent and its children in \n",
    "# the above. The second should just pass up unmodified the meaning of \n",
    "# its child node, so that the entire tree above is interpreted as \n",
    "# semantically equivalent to what 3rd means.\n",
    "\n",
    "# Add to the rules list here:\n",
    "\n",
    "\n",
    "\n",
    "######################################################################\n",
    "# Question 4: Rules for 4-digit years\n",
    "#\n",
    "# Long (4-digit) years are easy: they can be interpeted as themselves. \n",
    "# So these are rules of the form\n",
    "#\n",
    "#   $Y : int(year)\n",
    "#       |\n",
    "#      year\n",
    "#\n",
    "# where year is a 4-digit string.\n",
    "\n",
    "# This range will be fine for our data:\n",
    "years_long = [str(y) for y in range(1900, 2100)]\n",
    "\n",
    "# Add to the rules list here:\n",
    "\n",
    "\n",
    "\n",
    "######################################################################\n",
    "# Question 5: Rules for 2-digit years\n",
    "#\n",
    "# Two-digit years are ambiguous about their century. Intuitively, for \n",
    "# each 2-digit year, we need a rule for interpreting it in all \n",
    "# potential centuries:\n",
    "\n",
    "# All 2-digit years:\n",
    "years_short = [str(x).zfill(2) for x in range(0, 100)]\n",
    "# A suitable range of century multipliers given our data:\n",
    "centuries = range(1700, 2500, 100)       \n",
    "\n",
    "# Add to the rules list here:\n",
    "\n",
    "\n",
    "\n",
    "######################################################################\n",
    "########### INITIAL COMPOSITION RULES (ALREADY COMPLETED) ############\n",
    "#\n",
    "# Here are some initial composition rules. Together, these rules \n",
    "# create structures like this:\n",
    "#\n",
    "#           $DATE\n",
    "#           /    \\\n",
    "#   $MonthDay    $Y\n",
    "#    /     \\\n",
    "#   $M     $D\n",
    "#\n",
    "# and the 'dt' key connects with the ops dictionary we defined above.\n",
    "# The semantics is creating a tuple (dt year month day) for the\n",
    "# sake of date_semantics. You'll clearly need rules for at least\n",
    "# \n",
    "# * $MonthDay in the reverse order\n",
    "# * $Y before $MonthDay\n",
    "\n",
    "composition_rules = [\n",
    "    #                                                $M        $D\n",
    "    Rule('$MonthDay', '$M $D', lambda sems : ('dt', sems[0], sems[1])),\n",
    "    #                                           \n",
    "    Rule('$DATE', '$MonthDay $Y', \n",
    "    #                   dt            $Y       $M           $D\n",
    "         lambda sems: (sems[0][0], sems[1], sems[0][1], sems[0][2]))\n",
    "]\n",
    "\n",
    "\n",
    "######################################################################\n",
    "# Question 6: The remaining composition rules\n",
    "#\n",
    "# We need rules for\n",
    "#\n",
    "#    $MonthDay\n",
    "#     /     \\\n",
    "#    $D     $M\n",
    "#\n",
    "# and \n",
    "#   \n",
    "#      $DATE\n",
    "#      /    \\\n",
    "#     $Y  $MonthDay\n",
    "\n",
    "composition_rules += [\n",
    "    \n",
    "]\n",
    "\n",
    "rules += composition_rules\n",
    "\n",
    "######################################################################\n",
    "# Add all the rules to the grammar:\n",
    "\n",
    "for rule in rules:\n",
    "    add_rule(gram, rule)\n",
    "\n",
    "print('Grammar now has {} lexical rules, {} unary rules, '\n",
    "      'and {} binary rules'.format(\n",
    "          len(gram.lexical_rules), \n",
    "          len(gram.unary_rules), \n",
    "          len(gram.binary_rules)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your grammar should have \n",
    "\n",
    "* 366 lexical rules\n",
    "* 0 unary rules\n",
    "* 6 binary rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be informative to enter your own date strings and see what happens to them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from parsing import parse_to_pretty_string\n",
    "\n",
    "def parse_and_interpret(s, grammar=gram):\n",
    "    for i, parse in enumerate(gram.parse_input(s)):\n",
    "        print(\"=\" * 70)\n",
    "        print(\"Parse {}: {}\".format(i+1, parse_to_pretty_string(parse)))\n",
    "        print(\"Denotation: {}\".format(execute(parse.semantics)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parse_and_interpret(\"5 4 2015 US\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check oracle accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "You should be able to get 100% oracle accuracy with your grammar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_oracle_accuracy(grammar=None, examples=dateparse_train, verbose=True):\n",
    "    \"\"\"Use verbose=True to print out cases where your grammar can't\n",
    "    find a correct denotation among all of its parses.\"\"\"\n",
    "    oracle = 0\n",
    "    for ex in examples:\n",
    "        # All the denotations for all the parses:\n",
    "        dens = [execute(parse.semantics) for parse in gram.parse_input(ex.input)]\n",
    "        if ex.denotation in dens:\n",
    "            oracle += 1\n",
    "        elif verbose:\n",
    "            print(\"=\" * 70)\n",
    "            print(ex.input)\n",
    "            print(set(dens))\n",
    "            print(repr(ex.denotation))\n",
    "    percent_correct = oracle / float(len(examples))\n",
    "    print(\"Oracle accuracy: {0:} / {1:} ({2:0.02%})\".format(\n",
    "        oracle, len(examples), percent_correct))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_oracle_accuracy(\n",
    "    grammar=gram, examples=dateparse_train, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 7: Timezone sensitivity [2 points]\n",
    "\n",
    "As noted above, only Americans use the `month/day/year` order. This suggests that we can disambiguate otherwise ambiguous dates by writing a feature function that is sensitive to this pre-terminal ordering and the associated informal timezone string.\n",
    "\n",
    "__Your task__: Complete `timezone_sensitivity_features` so that, when given an input `parse`, it returns a `dict` of length 1 that maps the concatenation of the the timezone string and the pre-terminal nodes to `1`. You'll likely want to make use of `get_lemmas` and `get_timezone` to do this. (See `test_timezone_sensitivity_features` for a test, in case this description is ambiguous.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_timezone(parse):\n",
    "    \"\"\"Returns the timezone string in `parse`.\"\"\"\n",
    "    return parse.children[1].rule.rhs[0]\n",
    "\n",
    "\n",
    "def get_lemmas(parse):\n",
    "    \"\"\"Returns the list of (pre-terminal, word) pairs in `parse`.\"\"\"\n",
    "    labs = []\n",
    "    for t in parse.children:\n",
    "        if len(t.rule.rhs) == 1:\n",
    "            labs.append((t.rule.lhs, t.rule.rhs[0]))\n",
    "        else:\n",
    "            labs += get_lemmas(t)\n",
    "    return labs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timezone_sensitivity_features(parse):\n",
    "    feats = defaultdict(float)\n",
    "    \n",
    "    \n",
    "    return feats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's always a good measure to write a simple unit test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_timezone_sensitivity_features():\n",
    "    from parsing import Parse, Rule\n",
    "    \n",
    "    p = Parse(\n",
    "        Rule('$DATE', '$DATE $TZ'), \n",
    "        [Parse(\n",
    "            Rule('$DATE', '$MonthDay $Y'), \n",
    "            [Parse(Rule('$MonthDay', '$D $M'), \n",
    "                   [Parse(Rule('$D', '29'), ['29']), \n",
    "                    Parse(Rule('$M', 'Jun'), ['Jun'])]),\n",
    "             Parse(Rule('$Y', '1969'), ['1969'])]),\n",
    "         Parse(Rule('$TZ', 'non-US'), ['non-US'])])    \n",
    "    \n",
    "    expected = {'non-US $D $M $Y $TZ': 1}\n",
    "    result = timezone_sensitivity_features(p)    \n",
    "    if result == expected:\n",
    "        print(\"timezone_sensitivity_features test passed!\")\n",
    "    else:\n",
    "        raise AssertionError(\"timezone_sensitivity_features has a bug!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_timezone_sensitivity_features()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 8: Year-string length [2 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is another interesting bias in the data: throughout the latter half of the 20th century, people felt that they could give the year with just two digits, secure in the knowledge that this would somehow never be ambiguous (a rather depressing assumption). Let's capture this bias in a feature function.\n",
    "\n",
    "__Your task__: Complete `year_length_features` so that it returns a `dict` of length 1 in which the key has the form `$Ylen={LENGTH} year={YEAR}` where `LENGTH` is the length of the year string in the input and `YEAR` is the year field in the denotation. Return the empty dict if the denotation has no year. Tips: `get_lemmas` will make it easy to access the year string in the input, and `parse.denotation` is a `datetime.time` object from which it is easy to get the year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def year_length_features(parse):\n",
    "    feats = defaultdict(float)\n",
    "    \n",
    "    \n",
    "    return feats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a test for `year_length_features`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_year_length_features():\n",
    "    from parsing import Parse, Rule\n",
    "    \n",
    "    p = Parse(\n",
    "        Rule('$DATE', '$DATE $TZ'), \n",
    "        [Parse(\n",
    "            Rule('$DATE', '$MonthDay $Y'), \n",
    "            [Parse(Rule('$MonthDay', '$D $M'), \n",
    "                   [Parse(Rule('$D', '29'), ['29']), \n",
    "                    Parse(Rule('$M', 'Jun'), ['Jun'])]),\n",
    "             Parse(Rule('$Y', '69'), ['69'])]),\n",
    "         Parse(Rule('$TZ', 'non-US'), ['non-US'])])\n",
    "    \n",
    "    p.denotation = date(1969, 6, 29)\n",
    "            \n",
    "    expected = {'$Ylen=2 year=1969': 1}\n",
    "    result = year_length_features(p)\n",
    "    if result == expected:\n",
    "        print(\"year_length_features test passed!\")\n",
    "    else:\n",
    "        raise AssertionError(\"year_length_features has a bug!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_year_length_features()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting the feature functions together\n",
    "\n",
    "Here we just knit together `timezone_sensitivity_features` and `year_length_features` to train a model on both:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def date_rule_features(parse): \n",
    "    features = defaultdict(float)\n",
    "    features.update(timezone_sensitivity_features(parse))\n",
    "    features.update(year_length_features(parse))\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training step. Feel free to fiddle – longer optimization, lower learning rate – __but this is optional. It's fine to run this as-is and move on__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from learning import latent_sgd\n",
    "from metrics import DenotationAccuracyMetric\n",
    "from scoring import Model\n",
    "\n",
    "model = Model(grammar=gram, feature_fn=date_rule_features, executor=execute)\n",
    "\n",
    "trained_model = latent_sgd(\n",
    "    model, \n",
    "    dateparse_train,\n",
    "    loss='hinge',\n",
    "    l2_penalty=0,\n",
    "    training_metric=DenotationAccuracyMetric(), \n",
    "    T=10, \n",
    "    eta=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the trained model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now evaluate your model on the held-out data. __Nothing to do here beyond running the cell so that we can see the output printed in the notebook.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from experiment import evaluate_model\n",
    "from metrics import denotation_match_metrics\n",
    "\n",
    "evaluate_model(\n",
    "    model=trained_model, \n",
    "    examples=dateparse_dev,\n",
    "    examples_label=\"Dev\",\n",
    "    metrics=denotation_match_metrics(),\n",
    "    print_examples=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A rule-based baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Was it worth the trouble? I think it was, in that you probably soundly beat the high-performance `dateutil` parser. __Running the following is optional – purely in case you are curious about what the baseline achieves.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_dateutil(dataset, verbose=False):\n",
    "    \"\"\"dataset should be one data['train'] or data['dev']. Use\n",
    "    verbose=True to see information about the errors.\"\"\"\n",
    "    results = defaultdict(int)\n",
    "    for ex in dataset:\n",
    "        input = re.sub(r\"(non-)?US$\", \"\", ex.input)\n",
    "        prediction = None \n",
    "        try:\n",
    "            prediction = parser.parse(input).date()\n",
    "        except ValueError:\n",
    "            if verbose:\n",
    "                print(\"dateutil can't parse '%s'\" % input)\n",
    "        results[prediction == ex.denotation] += 1\n",
    "        if prediction and prediction != ex.denotation and verbose:\n",
    "            print(\"dateutil predicted %s to mean %s\" % (input, repr(prediction)))\n",
    "    acc = results[True] / float(len(dataset))\n",
    "    return \"accuracy: {0:} / {1:} ({2:0.2%})\".format(\n",
    "        results[True], len(dataset), acc)\n",
    "\n",
    "# Use verbose=True to see where and how dateutil stumbles:\n",
    "for key, data in (('train', dateparse_train), ('dev', dateparse_dev)):\n",
    "    print(\"{}: {}\".format(key, evaluate_dateutil(data, verbose=False)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect the trained model\n",
    "\n",
    "Which examples are you getting wrong? (Running this step is optional; it's recommended if you wish to improve the model by adding more features.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_errors(model=None, dataset=None, k=5):\n",
    "    data = copy.copy(dataset)\n",
    "    random.shuffle(data)\n",
    "    errors = 0\n",
    "    for i in range(len(data)):\n",
    "        ex = data[i]\n",
    "        parses = model.parse_input(ex.input)\n",
    "        if not parses or (parses[0].denotation != ex.denotation):\n",
    "            best_parse = parses[0] if parses else None\n",
    "            prediction = parses[0].denotation if parses else None\n",
    "            print(\"=\" * 70)\n",
    "            print('Input:', ex.input)\n",
    "            print('Best parse:', best_parse)\n",
    "            print('Prediction:', prediction)\n",
    "            print('Actual:', ex.denotation)\n",
    "            errors += 1\n",
    "            if errors >= k:\n",
    "                return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_errors(model=trained_model, dataset=dateparse_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
